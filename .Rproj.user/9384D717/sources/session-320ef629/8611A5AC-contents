---
title: "Métodos computacionales para las ciencias sociales"
subtitle: "Procesamiento de texto II"
format: 
    revealjs:
      auto-stretch: false
      scrollable: true
      link-external-newwindow: true
css: style.css
editor: source
execute:
  echo: true
---

## Contenidos de la clase

-   Uso básico de quanteda
-   quanteda + regex
-   Vectorización de textos

# ¿Por qué es relevante conocer herramientas para manejar *strings*? {.center background-color="aquamarine"}

## Introducción a quanteda

![](imagenes/logo_quanteda.png){fig-align="center" width="400px"}

Paquete para el procesamiento y análisis de texto

. . .

Mantenido por [Kenneth Benoit](https://kenbenoit.net/) y [Kohei Watanabe](https://blog.koheiw.net/){target="_blank"}

. . .

Ambos tienen una formación en ciencias sociales (ciencia política y literatura)

. . .

Documentación oficial [aquí](http://quanteda.io/index.html)

Tutoriales por [acá](https://tutorials.quanteda.io/)

## Primeros pasos

Es conveniente instalar todos los módulos

```{r, eval=FALSE}
install.packages("quanteda")
install.packages("quanteda.textstats")
install.packages("quanteda.textplots")



```

<br/>

```{r}
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
```

## Los datos

Conjunto de noticias obtenidas de los diarios La Razón y Público de España

Dataset obtenido de kaggle

. . .

```{r}
library(tidyverse)
data <- read_csv("data/data_larazon_publico_v2.csv")
```

![](imagenes/ejemplo_dataset.png){fig-align="center" width="1000px"}

## Flujo básico

::: panel-tabset

## crear corpus

Creamos un corpus a partir de una muestra del 20%

¡¡La columna se debe llamar *text*!!

```{r}
set.seed(123)
corp <- data %>% 
  select(text = cuerpo) %>% 
  sample_frac(0.2) %>% 
  corpus()
```

## corpus

```{r}
corp
```

## Características

```{r}
class(corp)
```

. . .

Es una especie de lista

```{r}
length(corp)
```
:::

## Crear tokens

::: panel-tabset

## tokenizar
```{r}
toks <-  corp %>% 
  tokens()
```

::: fragment

Es una especie de lista de listas

```{r}
toks
```
:::


## explorar

```{r}
toks[[1]]
toks[[1]][3]
```


## Todo junto

Usualmente, pasamos de corpus a tokens en una cadena de *pipes*

```{r, eval=FALSE}
toks <- data %>% 
  select(text = cuerpo) %>% 
  sample_frac(0.2) %>% 
  corpus() %>% 
  tokens()
```



:::


## Exploremos el dataset

Con `kwic` (*keyword in context*) podemos explorar 

```{r}
comentarios_eta <- toks %>% 
  kwic( pattern = "eta",  window = 7)  

```

```{r, echo=FALSE}
DT::datatable(comentarios_eta, options = list(pageLength = 3))

```




# Métodos computacionales para las ciencias sociales {.center background-color="aquamarine"}
